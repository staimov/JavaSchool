# Задание на практическую работу по модулю Kafka

### Задание #1 (Производители Kafka)
- Необходимо реализовать модуль для загрузки объектов в Kafka;
- Конфигурирование производителя должно быть вынесено в property-файл;
- В качестве данных необходимо сформировать объекты, описывающие транзакцию (тип операции/сумма/счёт/дата);
- Формат передачи данных JSON;
- Перед отправкой сообщения должны валидироваться по схеме json-schema;
- Разные типы операций должны записываться в разные партиции топика;
- Продюсер должен быть максимально производительным и гарантировать доставку всех транзакций брокеру;
- В случае сбоя продюсер должен фиксировать в логе ошибку, смещение и партицию битого сообщения;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;

### Задание #2 (Потребители Kafka)
- Необходимо реализовать модуль для выгрузки объектов из Kafka;
- Конфигурирование потребителя должно быть вынесено в property-файл;
- В качестве данных необходимо сформировать объекты, описывающие транзакцию (тип операции/сумма/счёт/дата);
- Формат передачи данных JSON;
- Перед обработкой сообщения должны валидироваться по схеме json-schema;
- Потребитель должен быть максимально производительным и гарантировать обработку всех транзакций брокера;
- В случае сбоя продюсер потребитель должен фиксировать текущий offset и при перезапуске начинать читать с него же;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;


### Задание #3 (Внутреннее устройство Kafka)
- Необходимо доработать производитель Kafka (из задания 1) для возможности получения подтверждения об успешной обработке событий через топик обратного потока;
- Вариант подтверждения - подсчитывать контрольную сумму по идентификаторам сообщений на основе временных срезов;
- В случае, если разойдутся контрольные суммы, необходимо повторить отправку всех битых сообщений;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;

### Задание #4 (Надёжность доставки данных)
- Необходимо доработать потребители Kafka (из задания 2) для возможности отправки подтверждения об успешной обработке событий через топик обратного потока;
- Вариант подтверждения - подсчитывать контрольную сумму по идентификаторам сообщений на основе временных срезов;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;

### Задание #5 (Конвейер данных)
- Изучить примеры файловых коннекторов в пакете sbp.school.kafka.connect;
- По примеру реализовать connector-plugin (на выбор source или sink) для любой реляционной БД;
- Для взаимодействия с БД можно использовать JDBC/Spring/Hibernate;
- В результате у вас должен получиться конвейер из БД в файл или из файла в БД;
- В качестве данных можно использовать транзакции из предыдущих заданий;
- Код должен быть задокументирован;
- Логируем все значимые кейсы;

### Задание #6* (Репликация данных)
- Создать необходимый для запуска MirrorMaker файл конфигурации производителя;
- Создать необходимый для запуска MirrorMaker файл конфигурации потребителя;
- Написать скрипт запуска MirrorMaker с использованием утилиты kafka-mirror-maker.sh;
- В скрипте запуска нужно учесть количество потоков, топики для репликации;

### Задание #7* (Инструменты работы с Kafka)
- В вашем распоряжении кластер с двумя брокерами и четырех партиций и фактором репликации = 2;
- В процессе эксплуатации системы замечено, что партиции 0 и 2 более загружены, чем остальные;
- Написать план (пошаговую инструкцию) выполнения смены распределения реплик партиций так, чтобы наиболее загруженные партиции были на разных брокерах (равномерное распределение нагрузки);
- Необходимо учесть сохранение текущего состояния на случай необходимости отката конфигурации;

### Задание #8* (Мониторинг Kafka)
- Предоставить конфигурацию для запуска брокера Kafka с доступом к параметрам для мониторинга по JMX;

### Задание #9* (Потоковая обработка)
- Написать механизм обогащения событий транзакций данными по клиенту из БД;
- В исходном топике в событии присутствует номер счета/карты;
- В выходном топике у событий должно быть ФИО клиента;
- Для реализации использовать Kafka Streams;
- В качестве БД можно использовать любое хранилище данных;

### Задание #10 (Тестирование Kafka)
- Дописать модульные тесты на все производители и потребители, разработанные в рамках выполнения домашних работ;

### Ограничения
- Не используем Spring или другие верхнеуровневые библиотеки.

### Как работать над заданием?
- Создаёте от main свою новую ветку с типом release и с именем по шаблону "Фамилия_Модуль_Задание" (например: release/taranov_kafka_1);
- Клонируете проект из новой ветки в локальный репозиторий;
- Делаете доработки у себя в локальном репозитории;
- Заливаете свои доработки в новую feature ветку (например feature/taranov_kafka_1);
- Делаете PR в свою исходную релизную ветку (из которой клонировали проект);

### Условие успешной сдачи работы (критерии приемки)
- Проект компилируется и запускается;
- Результат review PR = approve.